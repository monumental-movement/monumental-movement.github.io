import os
import yaml
import re
from deep_translator import GoogleTranslator
from difflib import unified_diff
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import lru_cache
import hashlib

# ---------------------------------------------
# è¨­å®š
# ---------------------------------------------
SRC_DIR = "_posts"
DEST_DIR = os.path.join("zh-hant", "_posts")
os.makedirs(DEST_DIR, exist_ok=True)

# ä¸¦åˆ—å‡¦ç†ã®ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ï¼ˆèª¿æ•´å¯èƒ½ï¼‰
MAX_WORKERS = 5

# ç¿»è¨³ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆãƒ¡ãƒ¢ãƒªå†…ï¼‰
translation_cache = {}

# Translator ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¯ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ã§ã¯ãªã„ãŸã‚ã€å„ã‚¹ãƒ¬ãƒƒãƒ‰ã§ç”Ÿæˆ
def get_translator():
    return GoogleTranslator(source='ja', target='zh-hant')


# =============================================
# ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ä»˜ãç¿»è¨³
# =============================================
def translate_text_cached(text, translator):
    if not isinstance(text, str):
        text = str(text)
    
    # ç©ºæ–‡å­—ã‚„çŸ­ã„æ–‡å­—åˆ—ã¯ãã®ã¾ã¾è¿”ã™
    if len(text.strip()) < 2:
        return text
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
    cache_key = hashlib.md5(text.encode()).hexdigest()
    if cache_key in translation_cache:
        return translation_cache[cache_key]
    
    try:
        result = translator.translate(text)
        if result is None:
            result = text
        else:
            result = str(result)
        translation_cache[cache_key] = result
        return result
    except Exception:
        return text


# =============================================
# ç¿»è¨³é™¤å¤–ãƒ–ãƒ­ãƒƒã‚¯ã®æŠ½å‡ºï¼ˆã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿æ­£è¦è¡¨ç¾ï¼‰
# =============================================
EXCLUDE_BLOCK_PATTERNS = [
    (re.compile(r"<style[\s\S]*?</style>", re.MULTILINE), "STYLE"),
    (re.compile(r"<script[\s\S]*?</script>", re.MULTILINE), "SCRIPT"),
    (re.compile(r"<table[\s\S]*?</table>", re.MULTILINE), "TABLE"),
    (re.compile(r"<div class=\"mermaid\"[\s\S]*?</div>", re.MULTILINE), "MERMAID-WRAP"),
]


def extract_excluded_blocks(text):
    placeholders = {}
    idx = 0

    for pattern, tag in EXCLUDE_BLOCK_PATTERNS:
        matches = list(pattern.finditer(text))
        for m in matches:
            block = m.group(0)
            placeholder = f"__EXCLUDE_{tag}_{idx}__"
            placeholders[placeholder] = block
            text = text.replace(block, placeholder)
            idx += 1

    return text, placeholders


def restore_excluded_blocks(text, placeholders):
    for ph, block in placeholders.items():
        text = text.replace(ph, block)
    return text


# =============================================
# Mermaid å†…ãƒãƒ¼ãƒ‰åãƒ»ã‚³ãƒ¡ãƒ³ãƒˆç¿»è¨³ï¼ˆæ­£è¦è¡¨ç¾ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ï¼‰
# =============================================
MERMAID_COMMENT_PATTERN = re.compile(r"%%\s*(.*)")
MERMAID_NODE_PATTERNS = [
    re.compile(r'(\[)(.*?)(\])'),
    re.compile(r'(\()([^()]*)(\))'),
    re.compile(r'(\(\()([^()]*)(\)\))'),
    re.compile(r'(\|)(.*?)(\|)'),
]
JAPANESE_PATTERN = re.compile(r'[ä¸€-é¾¯ã-ã‚“ã‚¡-ãƒ³]')


def translate_mermaid_line(line, translator):
    # ã‚³ãƒ¡ãƒ³ãƒˆç¿»è¨³
    def repl_comment(m):
        return "%% " + translate_text_cached(m.group(1), translator)
    line = MERMAID_COMMENT_PATTERN.sub(repl_comment, line)

    # ãƒãƒ¼ãƒ‰ãƒ©ãƒ™ãƒ«ç¿»è¨³
    for pat in MERMAID_NODE_PATTERNS:
        def repl(m):
            start, text, end = m.group(1), m.group(2), m.group(3)
            if JAPANESE_PATTERN.search(text):
                translated = translate_text_cached(text, translator)
                return f"{start}{translated}{end}"
            return m.group(0)
        line = pat.sub(repl, line)

    return line


# =============================================
# YAML front matter
# =============================================
def split_front_matter(content):
    if content.startswith("---"):
        parts = content.split('---', 2)
        if len(parts) >= 3:
            return parts[1], parts[2]
    return "", content


def load_yaml_safe(fm):
    try:
        return yaml.safe_load(fm) or {}
    except Exception:
        return {}


# =============================================
# URL slug ç”Ÿæˆ
# =============================================
@lru_cache(maxsize=128)
def extract_slug(filename):
    base = os.path.splitext(filename)[0]
    base = re.sub(r'^\d{4}-\d{2}-\d{2}-', '', base)
    slug = re.sub(r'[^\w]+', '-', base)
    return slug.lower().strip('-')


# =============================================
# å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
# =============================================
def process_file(filename):
    src_path = os.path.join(SRC_DIR, filename)
    dest_path = os.path.join(DEST_DIR, filename)

    with open(src_path, "r", encoding="utf-8") as f:
        src_content = f.read()

    # ç¿»è¨³é™¤å¤–ãƒ–ãƒ­ãƒƒã‚¯é€€é¿
    cleaned_body, placeholders = extract_excluded_blocks(src_content)

    # front matter æŠ½å‡º
    fm, body = split_front_matter(cleaned_body)
    front_matter = load_yaml_safe(fm)

    # å·®åˆ†ãƒã‚§ãƒƒã‚¯
    if os.path.exists(dest_path):
        with open(dest_path, "r", encoding="utf-8") as f:
            old = f.read()
        fm2, old_body = split_front_matter(old)
        diff = list(unified_diff(old_body.splitlines(), body.splitlines()))
        if not diff:
            return f"â­ï¸ No changes: {filename}"

    # Translator ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å–å¾—
    translator = get_translator()

    # ã‚¿ã‚¤ãƒˆãƒ«ç¿»è¨³
    if front_matter.get("title"):
        front_matter["title"] = translate_text_cached(front_matter["title"], translator)
        slug = extract_slug(filename)
        front_matter["lang"] = "zh-hant"
        front_matter["permalink"] = f"/zh-hant/{slug}/"

    # æœ¬æ–‡ç¿»è¨³
    translated_body = ""
    in_code_block = False
    in_mermaid_block = False

    for line in body.splitlines():
        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯
        if line.strip().startswith("```"):
            in_code_block = not in_code_block
            translated_body += line + "\n"
            continue

        if in_code_block:
            translated_body += line + "\n"
            continue

        # Mermaid ãƒ–ãƒ­ãƒƒã‚¯
        if line.strip().startswith("graph") or line.strip().startswith("flowchart"):
            in_mermaid_block = True
            translated_body += line + "\n"
            continue

        if in_mermaid_block:
            if line.strip() == "":
                translated_body += line + "\n"
                continue
            translated_body += translate_mermaid_line(line, translator) + "\n"
            continue

        if line.strip() == "</div>":
            in_mermaid_block = False
            translated_body += line + "\n"
            continue

        # é€šå¸¸è¡Œç¿»è¨³
        translated_body += translate_text_cached(line, translator) + "\n"

    # é™¤å¤–ãƒ–ãƒ­ãƒƒã‚¯å¾©å…ƒ
    final_output = restore_excluded_blocks(
        f"---\n{yaml.safe_dump(front_matter, allow_unicode=True)}---\n{translated_body}",
        placeholders
    )

    with open(dest_path, "w", encoding="utf-8") as f:
        f.write(final_output)

    return f"âœ… Translated: {filename}"


# =============================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼ˆä¸¦åˆ—åŒ–ï¼‰
# =============================================
if __name__ == "__main__":
    files = [f for f in os.listdir(SRC_DIR) if f.endswith(".md")]
    
    print(f"ğŸš€ Processing {len(files)} files with {MAX_WORKERS} workers...\n")
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(process_file, f): f for f in files}
        
        for future in as_completed(futures):
            result = future.result()
            print(result)

    print(f"\nğŸ‰ zh-hant translation completed!")
    print(f"ğŸ“Š Cache size: {len(translation_cache)} entries")